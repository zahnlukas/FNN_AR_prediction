{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from feature_scaler import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_nr = 5\n",
    "\n",
    "X_train = pd.read_csv(f\"Inputs/Dataset_{dataset_nr}/X_train.csv\")\n",
    "y_train = pd.read_csv(f\"Inputs/Dataset_{dataset_nr}/y_train.csv\")\n",
    "X_val = pd.read_csv(f\"Inputs/Dataset_{dataset_nr}/X_val.csv\")\n",
    "y_val = pd.read_csv(f\"Inputs/Dataset_{dataset_nr}/y_val.csv\")\n",
    "X_test = pd.read_csv(f\"Inputs/Dataset_{dataset_nr}/X_test.csv\")\n",
    "y_test = pd.read_csv(f\"Inputs/Dataset_{dataset_nr}/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, Embedding, Flatten, Concatenate\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt\n",
    "import time\n",
    "\n",
    "# Number of features in the model\n",
    "n_features = X_train.shape[1]\n",
    "\n",
    "# Number of unique customers\n",
    "n_unique_customers = X_train['customer_id_enc'].nunique()\n",
    "embedding_dim = int(sqrt(n_unique_customers))\n",
    "\n",
    "\n",
    "# Number unique countries\n",
    "n_unique_countries = X_train['country_enc'].nunique()\n",
    "embedding_dim_country = int(sqrt(n_unique_countries))\n",
    "\n",
    "#Initialize result list\n",
    "results = []\n",
    "\n",
    "# Prepare the data; extract customer_id and country for embedding layers\n",
    "X_train_customer_id = X_train['customer_id_enc'].values\n",
    "X_train_country = X_train['country_enc'].values\n",
    "X_train_other_features = X_train.drop(columns=['customer_id_enc', 'country_enc']).values\n",
    "\n",
    "X_val_customer_id = X_val['customer_id_enc'].values\n",
    "X_val_country = X_val['country_enc'].values\n",
    "X_val_other_features = X_val.drop(columns=['customer_id_enc', 'country_enc']).values\n",
    "\n",
    "# Extract the test features\n",
    "X_test_customer_id = X_test['customer_id_enc'].values\n",
    "X_test_country = X_test['country_enc'].values\n",
    "X_test_other_features = X_test.drop(columns=['customer_id_enc', 'country_enc']).values\n",
    "\n",
    "\n",
    "#Define Model 3:\n",
    "def model_3(n_unique_customers, n_unique_countries, n_features):\n",
    "    \n",
    "    # Input layers\n",
    "    customer_id_input = Input(shape=(1,), name='customer_id_input')  # Input for customer_id_enc\n",
    "    country_input = Input(shape=(1,), name='country_input')  # Input for country_enc\n",
    "    other_features_input = Input(shape=(n_features - 2,), name='other_features_input')  # Input for other features, excluding customer_id_enc and country_enc\n",
    "\n",
    "    # Embedding layer for customer_id_enc; input_dim + 1 to account for unseen categories in test set\n",
    "    customer_id_embedding = Embedding(input_dim=n_unique_customers + 1, output_dim=embedding_dim)(customer_id_input)\n",
    "    customer_id_embedding = Flatten()(customer_id_embedding) # Flatten the embedding (from 2D to 1D)\n",
    "\n",
    "    # Embedding layer for country_enc\n",
    "    country_embedding = Embedding(input_dim=n_unique_countries + 1, output_dim=embedding_dim_country)(country_input)\n",
    "    country_embedding = Flatten()(country_embedding)  # Flatten the embedding (from 2D to 1D)\n",
    "\n",
    "\n",
    "    # Concatenate embeddings with other features\n",
    "    concatenated = Concatenate()([customer_id_embedding, country_embedding, other_features_input])\n",
    "\n",
    "    # Add Dense layers\n",
    "    x = Dense(128, activation=\"relu\")(concatenated)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "\n",
    "    # Output layer with 1 neuron\n",
    "    output = Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=[customer_id_input, country_input,other_features_input], outputs=output)\n",
    "\n",
    "    # Configure the model\n",
    "    model.compile(optimizer='adam', loss=\"mean_squared_error\", metrics=[\"mean_absolute_error\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "# training loop 5 times:\n",
    "for run in range(1,6):\n",
    "    print(f\"Run {run}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model = model_3(n_unique_customers, n_unique_countries, n_features)\n",
    "    checkpoint = ModelCheckpoint(f'learned_models/Model_3/data_{dataset_nr}_run_{run}.keras', monitor='val_loss', save_best_only=True, mode='min')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    \n",
    "    model.fit([X_train_customer_id, X_train_country, X_train_other_features], y_train, \n",
    "              validation_data=([X_val_customer_id, X_val_country ,X_val_other_features], y_val), \n",
    "              epochs=20, batch_size=256, callbacks=[checkpoint, early_stopping])\n",
    "    \n",
    "    best_model = load_model(f'learned_models/Model_3/data_{dataset_nr}_run_{run}.keras')\n",
    "    \n",
    "        # Evaluate the best model of each run at the end\n",
    "    y_pred = best_model.predict([X_test_customer_id, X_test_country, X_test_other_features])\n",
    "    mae = mean_absolute_error(y_test.values, y_pred)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    run_time = end_time - start_time\n",
    "    \n",
    "    results.append((run, mae, run_time))\n",
    "\n",
    "# Store results in a DataFrame\n",
    "results_df = pd.DataFrame(results, columns=['Run', 'MAE', 'Run Time'])\n",
    "\n",
    "# Save the DataFrame to a CSV file in the current directory\n",
    "results_df.to_csv(f'Results_df/Model_3/Data_{dataset_nr}.csv', index=False)\n",
    "\n",
    "# Compute average MAE, standard deviation, and average running time\n",
    "average_mae = results_df['MAE'].mean()\n",
    "std_mae = results_df['MAE'].std()\n",
    "average_run_time = results_df['Run Time'].mean()\n",
    "\n",
    "print(\"Results DataFrame:\")\n",
    "print(results_df)\n",
    "print(f\"Average MAE: {round(average_mae, ndigits=2)}\")\n",
    "print(f\"Standard Deviation of MAE: {round(std_mae, ndigits=2)}\")\n",
    "print(f\"Average Running Time: {round(average_run_time, ndigits=2)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number unique customers: \", n_unique_customers)\n",
    "print(\"Embedding dimensions Customer ID: \", embedding_dim)\n",
    "print(\"Number unique countries: \", n_unique_countries)\n",
    "print(\"Embedding dimensions Country: \", embedding_dim_country)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing performance on Test set with also new customers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error\n",
    "\n",
    "# Testing with new customers:\n",
    "dataset_nr = 5\n",
    "X_test_all = pd.read_csv(f\"Inputs/Dataset_{dataset_nr}/X_test_all_customers.csv\")\n",
    "y_test_all = pd.read_csv(f\"Inputs/Dataset_{dataset_nr}/y_test_all_customers.csv\")\n",
    "\n",
    "\n",
    "# Comparison without new customers\n",
    "X_test_subset = pd.read_csv(f\"Inputs/Dataset_{dataset_nr}/X_test.csv\")\n",
    "y_test_subset = pd.read_csv(f\"Inputs/Dataset_{dataset_nr}/y_test.csv\")\n",
    "\n",
    "\n",
    "best_model = load_model('learned_models/Model_3/data_5_run_3.keras')\n",
    "\n",
    "\n",
    "### Results for Dataset with new customers\n",
    "\n",
    "X_test_customer_id = X_test_all['customer_id_enc'].values\n",
    "X_test_country = X_test_all['country_enc'].values\n",
    "X_test_other_features = X_test_all.drop(columns=['customer_id_enc', 'country_enc']).values\n",
    "\n",
    "\n",
    "# Make predictions on X_test_subset\n",
    "predicted_values = best_model.predict([X_test_customer_id, X_test_country, X_test_other_features])\n",
    "\n",
    "# Convert the predicted values to a DataFrame\n",
    "predicted_df = pd.DataFrame(predicted_values, columns=['Predicted'])\n",
    "\n",
    "# Optionally, add the actual values for comparison\n",
    "actual_df = pd.DataFrame(y_test_all.values, columns=['Actual'])\n",
    "df_comparison = pd.concat([actual_df, predicted_df], axis=1)\n",
    "# Round the predicted values\n",
    "df_comparison['Predicted'] = np.round(df_comparison['Predicted'])\n",
    "\n",
    "\n",
    "### Results for Dataset without new customers for comparison\n",
    "\n",
    "X_test_customer_id_subset = X_test_subset['customer_id_enc'].values\n",
    "X_test_country_subset = X_test_subset['country_enc'].values\n",
    "X_test_other_features_subset = X_test_subset.drop(columns=['customer_id_enc', 'country_enc']).values\n",
    "\n",
    "predicted_values_subset = best_model.predict([X_test_customer_id_subset, X_test_country_subset, X_test_other_features_subset])\n",
    "\n",
    "predicted_df_subset = pd.DataFrame(predicted_values_subset, columns=['Predicted'])\n",
    "\n",
    "actual_df_subset = pd.DataFrame(y_test_subset.values, columns=['Actual'])\n",
    "df_comparison_subset = pd.concat([actual_df_subset, predicted_df_subset], axis=1)\n",
    "df_comparison_subset['Predicted'] = np.round(df_comparison_subset['Predicted'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Shape of X_test without new customers: \", X_test_subset.shape)\n",
    "MAE_subset = mean_absolute_error(df_comparison_subset['Actual'], df_comparison_subset['Predicted'])\n",
    "MedAE_subset = median_absolute_error(df_comparison_subset['Actual'], df_comparison_subset['Predicted'])\n",
    "print(f\"Mean Absolute without new customers Error: {round(MAE_subset, ndigits=2)}\")\n",
    "print(f\"Median Absolute without new customers Error: {round(MedAE_subset, ndigits=2)}\")\n",
    "print('------------------------------------------------')\n",
    "print(\"Shape of X_test with new customers: \", X_test_all.shape)\n",
    "MAE = mean_absolute_error(df_comparison['Actual'], df_comparison['Predicted'])\n",
    "MedAE = median_absolute_error(df_comparison['Actual'], df_comparison['Predicted'])\n",
    "print(f\"Mean Absolute with new customers Error: {round(MAE, ndigits=2)}\")\n",
    "print(f\"Median Absolute with new customers Error: {round(MedAE, ndigits=2)}\")\n",
    "print('------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
