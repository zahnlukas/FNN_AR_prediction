{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from  feature_scaler import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1\n",
    "\n",
    "In this notebook Model 1 is tested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data & prepare dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare which dataset want to evaluate; hyperparameter for evaluation\n",
    "dataset_nr = 5\n", 
    "\n",
    "X_train = pd.read_csv(f\"Inputs/Dataset_{dataset_nr}/X_train.csv\")\n",
    "y_train = pd.read_csv(f\"Inputs/Dataset_{dataset_nr}/y_train.csv\")\n",
    "X_val = pd.read_csv(f\"Inputs/Dataset_{dataset_nr}/X_val.csv\")\n",
    "y_val = pd.read_csv(f\"Inputs/Dataset_{dataset_nr}/y_val.csv\")\n",
    "X_test = pd.read_csv(f\"Inputs/Dataset_{dataset_nr}/X_test.csv\")\n",
    "y_test = pd.read_csv(f\"Inputs/Dataset_{dataset_nr}/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Input\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import time\n",
    "\n",
    "\n",
    "# Define the model creation function\n",
    "def create_model(n_features):\n",
    "    model = Sequential() # Define a sequential model (FNN)\n",
    "    model.add(Input(shape=(n_features,))) # Input layer\n",
    "    model.add(Dense(128, activation=\"relu\"))  # layer 1\n",
    "    model.add(Dense(64, activation=\"relu\"))  # layer 2\n",
    "    model.add(Dense(1, activation=\"linear\"))  # output layer\n",
    "    model.compile(optimizer='adam', loss=\"mean_squared_error\", metrics=[\"mean_absolute_error\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "#Define input shape\n",
    "n_features = X_train.shape[1]\n",
    "\n",
    "#Initialize results list\n",
    "results = [] \n",
    "\n",
    "# Train and evaluate the model 10 times\n",
    "for run in range(1, 11):\n",
    "    print(f\"Run {run}\")\n",
    "    start_time = time.time() #Track running time\n",
    "    \n",
    "    model = create_model(n_features) \n",
    "    \n",
    "    #Define checkpoint: Saves model at epoch with best validation loss\n",
    "    checkpoint = ModelCheckpoint(f'learned_models/Model_1/data_{dataset_nr}_run_{run}.keras', monitor='val_loss', save_best_only=True, mode='min') \n",
    "    # Early stopping after 5 epochs without improvement\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    model.fit(X_train.values, y_train.values, validation_data=(X_val.values, y_val.values), epochs=20, batch_size=256, callbacks=[checkpoint], verbose = 0)\n",
    "    \n",
    "    #Save best model for prediction (important beacuse overfitting may cause the best model to be in the middle of the training process)\n",
    "    best_model = load_model(f'learned_models/Model_1/data_{dataset_nr}_run_{run}.keras')   #update with each dataset!\n",
    "    \n",
    "    # Evaluate the best model of each run at the end\n",
    "    y_pred = best_model.predict(X_test.values) # Predictions of test data\n",
    "    mae = mean_absolute_error(y_test.values, y_pred) # MAE of test data\n",
    "    \n",
    "    end_time = time.time() \n",
    "    run_time = end_time - start_time #Calculate run time of each run\n",
    "    \n",
    "    results.append((run, mae, run_time))\n",
    "\n",
    "# Store results in a DataFrame\n",
    "results_df = pd.DataFrame(results, columns=['Run', 'MAE', 'Run Time'])\n",
    "\n",
    "# Save the dataframe\n",
    "results_df.to_csv(f'Results_df/Model_1/Data_{dataset_nr}.csv', index=False)\n",
    "\n",
    "\n",
    "# Compute average MAE, standard deviation, and average running time\n",
    "average_mae = results_df['MAE'].mean()\n",
    "std_mae = results_df['MAE'].std()\n",
    "average_run_time = results_df['Run Time'].mean()\n",
    "\n",
    "print(\"Results DataFrame:\")\n",
    "print(results_df)\n",
    "print(f\"Average MAE: {round(average_mae, ndigits=2)}\")\n",
    "print(f\"Standard Deviation of MAE: {round(std_mae, ndigits=2)}\")\n",
    "print(f\"Average Running Time: {round(average_run_time, ndigits=2)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print architecture of model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing performance on new customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import mean_absolute_error\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "dataset_nr = 5\n",
    "X_test = pd.read_csv(f\"Inputs/Dataset_{dataset_nr}/X_test_all_customers.csv\")\n",
    "y_test = pd.read_csv(f\"Inputs/Dataset_{dataset_nr}/y_test_all_customers.csv\")\n",
    "X_test_subset = pd.read_csv(f\"Inputs/Dataset_{dataset_nr}/X_test.csv\")\n",
    "y_test_subset = pd.read_csv(f\"Inputs/Dataset_{dataset_nr}/y_test.csv\")\n",
    "\n",
    "\n",
    "#Define model learned from cell above\n",
    "best_model = load_model('learned_models/Model_1/data_5_run_10.keras')\n",
    "\n",
    "#Predictions on X_test subset\n",
    "predicted_values_subset = best_model.predict(X_test_subset.values)\n",
    "\n",
    "# Make predictions on X_test\n",
    "predicted_values = best_model.predict(X_test.values)\n",
    "\n",
    "# Convert the predicted values to a DataFrame\n",
    "predicted_df_subset = pd.DataFrame(predicted_values_subset, columns=['Predicted'])\n",
    "actual_df_subset = pd.DataFrame(y_test_subset.values, columns=['Actual'])\n",
    "df_comparison_subset = pd.concat([actual_df_subset, predicted_df_subset], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convert the predicted values to a DataFrame\n",
    "predicted_df = pd.DataFrame(predicted_values, columns=['Predicted'])\n",
    "# Optionally, add the actual values for comparison\n",
    "actual_df = pd.DataFrame(y_test.values, columns=['Actual'])\n",
    "df_comparison = pd.concat([actual_df, predicted_df], axis=1)\n",
    "\n",
    "\n",
    "print(\"Shape of X_test without new customers: \", X_test_subset.shape)\n",
    "print(\"Shape of X_test with new customers: \", X_test.shape)\n",
    "print('------------------------------------------------')\n",
    "MAE_subset = mean_absolute_error(df_comparison_subset['Actual'], df_comparison_subset['Predicted'])\n",
    "print(f\"Mean Absolute Error without new customers: {round(MAE_subset, ndigits= 2)}\")\n",
    "print('------------------------------------------------')\n",
    "MAE = mean_absolute_error(df_comparison['Actual'], df_comparison['Predicted'])\n",
    "print(f\"Mean Absolute Error with new customers: {round(MAE, ndigits= 2)}\")\n",
    "print('------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
