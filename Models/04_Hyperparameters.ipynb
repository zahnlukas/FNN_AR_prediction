{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras_tuner import  RandomSearch\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Embedding, Concatenate\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from math import sqrt\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_nr = 5\n",
    "\n",
    "X_train = pd.read_csv(f\"Inputs/Dataset_{dataset_nr}/X_train.csv\")\n",
    "y_train = pd.read_csv(f\"Inputs/Dataset_{dataset_nr}/y_train.csv\")\n",
    "X_val = pd.read_csv(f\"Inputs/Dataset_{dataset_nr}/X_val.csv\")\n",
    "y_val = pd.read_csv(f\"Inputs/Dataset_{dataset_nr}/y_val.csv\")\n",
    "X_test = pd.read_csv(f\"Inputs/Dataset_{dataset_nr}/X_test.csv\")\n",
    "y_test = pd.read_csv(f\"Inputs/Dataset_{dataset_nr}/y_test.csv\")\n",
    "\n",
    "# Define input shape\n",
    "n_features = X_train.shape[1]\n",
    "\n",
    "# Number of unique customers\n",
    "n_unique_customers = X_train['customer_id_enc'].nunique()\n",
    "embedding_dim = int(sqrt(n_unique_customers))\n",
    "\n",
    "# Number unique countries\n",
    "n_unique_countries = X_train['country_enc'].nunique()\n",
    "embedding_dim_country = int(sqrt(n_unique_countries))\n",
    "\n",
    "# Prepare the data\n",
    "X_train_customer_id = X_train['customer_id_enc'].values\n",
    "X_train_country = X_train['country_enc'].values\n",
    "X_train_other_features = X_train.drop(columns=['customer_id_enc', 'country_enc']).values\n",
    "\n",
    "X_val_customer_id = X_val['customer_id_enc'].values\n",
    "X_val_country = X_val['country_enc'].values\n",
    "X_val_other_features = X_val.drop(columns=['customer_id_enc', 'country_enc']).values\n",
    "\n",
    "# Extract the test features\n",
    "X_test_customer_id = X_test['customer_id_enc'].values\n",
    "X_test_country = X_test['country_enc'].values\n",
    "X_test_other_features = X_test.drop(columns=['customer_id_enc', 'country_enc']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    \n",
    "    # Input layers\n",
    "    customer_id_input = Input(shape=(1,), name='customer_id_input')  # Input for customer_id_enc\n",
    "    country_input = Input(shape=(1,), name='country_input')  # Input for country_enc\n",
    "    other_features_input = Input(shape=(n_features - 2,), name='other_features_input')  # Input for other features, excluding customer_id_enc and country_enc\n",
    "\n",
    "    # Embedding layer for customer_id_enc; input_dim + 1 to account for unseen categories in test set\n",
    "    customer_id_embedding = Embedding(input_dim=n_unique_customers + 1, output_dim=embedding_dim)(customer_id_input)\n",
    "    customer_id_embedding = Flatten()(customer_id_embedding) # Flatten the embedding (from 2D to 1D)\n",
    "\n",
    "    # Embedding layer for country_enc\n",
    "    country_embedding = Embedding(input_dim=n_unique_countries + 1, output_dim=embedding_dim_country)(country_input)\n",
    "    country_embedding = Flatten()(country_embedding)  # Flatten the embedding (from 2D to 1D)\n",
    "\n",
    "\n",
    "    # Concatenate embeddings with other features\n",
    "    x = Concatenate()([customer_id_embedding, country_embedding, other_features_input])\n",
    "    \n",
    "    \"\"\"\n",
    "    For loop: each time model can have between 1 and 5 hidden layers, based of the number of hidden layers ramdomly selected,\n",
    "    a random number of neurons out of the specified values will be selected for each layer. \n",
    "    Additionally a dropout layer is added after each hidden layer to prevent overfitting, the dropout ratio is also randomly selected between 0 and 0.5.\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(hp.Int('num_layers', min_value = 1, max_value = 5)): # possible n layers: [1,2,3,4,5]\n",
    "        \n",
    "        \n",
    "        x = Dense(units=hp.Choice(f'units_{i}', values = [32, 64, 128, 256], ordered = True), activation='relu')(x)\n",
    "        \n",
    "        # tune dropout ratio:\n",
    "        x = Dropout(rate = hp.Float(f\"dropout_{i}\",\n",
    "                                    min_value = 0,\n",
    "                                    max_value = 0.5))(x)\n",
    "    \n",
    "    output = Dense(1, activation='linear')(x)\n",
    "    \n",
    "    model = Model(inputs=[customer_id_input, country_input,other_features_input], outputs=output)\n",
    "    \n",
    "    \"\"\"\n",
    "    A random float lr is selected for each model beteen 0.00001 and 0.1, with a logarithmic sampling,\n",
    "    meaning that the values are sampled uniformly on a log scale (0.00001; 0.0001; 0.001; 0.01; 0.1)\n",
    "    \"\"\"\n",
    "    \n",
    "    #Assess different values for learning rate\n",
    "    learning_rate = hp.Float(\"lr\",\n",
    "                             min_value = 1e-5,\n",
    "                             max_value = 1e-1,\n",
    "                             step = 10,\n",
    "                             sampling = \"log\") # logarithmic sampling; range: min_value * (max_value / min_value) ^ step\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate = learning_rate), loss=\"mean_squared_error\", metrics=[\"mean_absolute_error\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "#Select tuner class to run search with RandomSearch\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    hypermodel = build_model,\n",
    "    objective = \"val_mean_absolute_error\",\n",
    "    max_trials = 100, # Total number of trials to run during hyperparameter search; 1 trial has 1 type of hyperparameter configuration; 100 configuations will be evaluated\n",
    "    executions_per_trial = 3, # Number of models to train per trial, to account for randomness in model initialization\n",
    "    overwrite = True, # Overwrite the results of the previous tuning run\n",
    "    directory = \"tuning_dir\", # Directory to store tuning results\n",
    "    project_name = \"DSO_predictor\")\n",
    "\n",
    "\n",
    "# Print the summary of the search space\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement early stopping, after 3 epochs without improvement in validation mean absolute error, the training will stop\n",
    "early_stopping = EarlyStopping(monitor = \"val_mean_absolute_error\", patience = 3, restore_best_weights = True)\n",
    "\n",
    "tuner.search([X_train_customer_id, X_train_country, X_train_other_features],  y_train,\n",
    "             epochs = 10,\n",
    "             validation_data=([X_val_customer_id, X_val_country, X_val_other_features], y_val),\n",
    "             batch_size = 256,\n",
    "             callbacks = [early_stopping]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save two best model configuratio, i.e. the two models with the lowest validation mean absolute error\n",
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model \n",
    "best_model.save(\"learned_models/tuned/final_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model performance when trained on merged train and evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model(\"learned_models/tuned/final_model.keras\")\n",
    "\n",
    "# Retrain the model with entire dataset\n",
    "Train_customer_all = np.concatenate((X_train_customer_id, X_val_customer_id))\n",
    "Train_country_all = np.concatenate((X_train_country, X_val_country))\n",
    "Train_other_features_all = np.concatenate((X_train_other_features, X_val_other_features))\n",
    "y_train_all = np.concatenate((y_train, y_val))\n",
    "\n",
    "best_model.fit([Train_customer_all, Train_country_all, Train_other_features_all], y_train_all, epochs = 15, batch_size = 256)\n",
    "\n",
    "test_loss, test_mae = best_model.evaluate([X_test_customer_id, X_test_country, X_test_other_features], y_test)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test MAE: {test_mae}\")\n",
    "\n",
    "# Make predictions on X_test_subset\n",
    "predicted_values = best_model.predict([X_test_customer_id, X_test_country, X_test_other_features])\n",
    "\n",
    "# Convert the predicted values to a DataFrame\n",
    "predicted_df = pd.DataFrame(predicted_values, columns=['Predicted'])\n",
    "\n",
    "# Optionally, add the actual values for comparison\n",
    "actual_df = pd.DataFrame(y_test.values, columns=['Actual'])\n",
    "df_comparison = pd.concat([actual_df, predicted_df], axis=1)\n",
    "\n",
    "print('------------------------------------------------')\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "MAE = mean_absolute_error(df_comparison['Actual'], df_comparison['Predicted'])\n",
    "print(f\"Mean Absolute Error: {round(MAE, ndigits= 2)}\")\n",
    "print('------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
