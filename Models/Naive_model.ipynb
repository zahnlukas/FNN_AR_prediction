{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive prediction - benchmark\n",
    "\n",
    "With this naive prediction we want to create a \"baseline\" model, where we calculate the avg_dso for the customers in X_train and use it as \"prediction\" for the payments of those customers in the side_data (newest ARs). The goal is to create a model that performs better than this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('EDA_and_feature_analysis/data/Model_1_and_2.csv')\n",
    "\n",
    "#reset index\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by date\n",
    "df = df.sort_values('weighted_payment_date')\n",
    "\n",
    "# Determine the split index\n",
    "split_index = int(len(df) * 0.8)\n",
    "\n",
    "# Find the payment date at split_index\n",
    "date_train_split = df.iloc[split_index]['weighted_payment_date']\n",
    "\n",
    "# Splitting main and side data based on date_train_split; side_data used for validation and test\n",
    "X_train = df[df['weighted_payment_date'] <= date_train_split]\n",
    "side_data = df[df['weighted_payment_date'] > date_train_split]\n",
    "\n",
    "# Determine the split index\n",
    "split_index_test = int(len(side_data) * 0.5)\n",
    "\n",
    "# Find the payment date at split_index\n",
    "date_val_split = side_data.iloc[split_index_test]['weighted_payment_date']\n",
    "\n",
    "# Splitting the test data to be same as in the other models\n",
    "test_data = side_data[side_data['weighted_payment_date'] > date_val_split]\n",
    "\n",
    "\n",
    "#Store unique customer ids from train data\n",
    "unique_customer_ids_train = X_train['customer_id'].unique()\n",
    "\n",
    "# Create a boolean mask for rows in the side data with customer_ids that are in the main data\n",
    "mask_test_data = test_data['customer_id'].isin(unique_customer_ids_train)\n",
    "\n",
    "# Create subset of side_data containing only customer_ids that are in the main data\n",
    "test_data_subset = test_data[mask_test_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train data shape: \", X_train.shape)\n",
    "print(\"Side data shape: \", side_data.shape)\n",
    "print(\" \")\n",
    "print(\"-------------------------\")\n",
    "print(\"Test if it worked:\") #printing the earliest and latest dates in the train and test sets\n",
    "print(\"Earliest payment date in Train data: \", X_train['weighted_payment_date'].min())\n",
    "print(\"Latest payment date in Train data: \", X_train['weighted_payment_date'].max())\n",
    "print(\"Earliest payment date in test_data: \", test_data['weighted_payment_date'].min())\n",
    "print(\"Latest payment  date in test_data: \", test_data['weighted_payment_date'].max())\n",
    "print(\"-------------------------\")\n",
    "print(\"Test data shape: \", test_data.shape)\n",
    "print(\"Test data subset shape: \", test_data_subset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[['customer_id', 'receipt_date', 'dso']]\n",
    "test_data_subset = test_data_subset[['customer_id', 'receipt_date', 'dso']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of avg_dso as prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate average dso for each customer\n",
    "tmp = X_train.groupby(\"customer_id\")[\"dso\"].mean()\n",
    "\n",
    "# Create new column avg_dso\n",
    "X_train[\"avg_dso\"] = X_train[\"customer_id\"].map(tmp)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates in X_train\n",
    "avg_dso_customer = X_train.drop_duplicates(subset=['customer_id', 'avg_dso'])\n",
    "\n",
    "# merge the avg_dso column from the train data to the side data\n",
    "test_data_subset = test_data_subset.merge(avg_dso_customer[['customer_id', 'avg_dso']], on='customer_id')\n",
    "\n",
    "test_data_subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------------------------------------------')  \n",
    "#print the MAE of the total dataset\n",
    "MAE = np.mean(abs(test_data_subset['dso'] - test_data_subset['avg_dso']))\n",
    "median_AE = median_absolute_error(test_data_subset['dso'], test_data_subset['avg_dso'])\n",
    "\n",
    "print(f\"Mean Absolute Error: {round(MAE, ndigits= 2)}\")\n",
    "print('------------------------------------------------')\n",
    "print(f\"Median Absolute Error: {round(median_AE, ndigits= 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of dso and predicted dso\n",
    "\n",
    "test_data_subset['avg_dso'].plot(kind = 'hist', bins = 50, rwidth = 0.8, alpha = 0.5, label = 'avg_dso')\n",
    "test_data_subset['dso'].plot(kind = 'hist', bins = 50, rwidth = 0.8, alpha = 0.5, label = 'dso')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
